{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'all_log_files.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 10\u001b[0m\n\u001b[1;32m      7\u001b[0m line_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Open the file and count the lines\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m file:\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m file:\n\u001b[1;32m     12\u001b[0m         line_count \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/6spEnv/lib/python3.8/site-packages/IPython/core/interactiveshell.py:284\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    277\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[1;32m    278\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    279\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    280\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    281\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    282\u001b[0m     )\n\u001b[0;32m--> 284\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'all_log_files.txt'"
     ]
    }
   ],
   "source": [
    "# Counting no. of lines ( i.e. no. of .csv file in the all_log_file.txt)\n",
    "\n",
    "# Specify the path to your .txt file\n",
    "file_path = 'all_log_files.txt'\n",
    "\n",
    "# Initialize a line counter\n",
    "line_count = 0\n",
    "                                                                                                                                                                                                                                                                                                                                                                    \n",
    "# Open the file and count the lines\n",
    "with open(file_path, 'r') as file:\n",
    "    for line in file:\n",
    "        line_count += 1\n",
    "\n",
    "# Print the line count\n",
    "print(f\"Number of lines in '{file_path}': {line_count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "# Define the range and the exclusion list\n",
    "min_range = 0\n",
    "max_range = 18336\n",
    "exclusion_list = [16011, 2385, 15407, 5606, 5329, 16689, 9025, 5903, 6458, 11808, 10506, 15727, 368, 5897, 2544, 16788, 9602, 5088, 16948, 1624, 1815, 3710, 17352, 14198, 1455, 8540, 2693, 1692, 12142, 15946, 7743, 5828, 3210, 9623, 3309, 5862, 15515, 17061, 5316, 740, 6778, 7630, 6077, 15017, 7736, 9334, 2072, 17994, 13999, 13271, 8601, 10831, 5183, 8116, 6840, 14999, 17223, 13134, 10123, 16709, 17704, 11989, 16706, 10749, 9170, 2174, 5113, 11753, 14561, 4542, 16326, 16959, 13155, 6379, 8613, 8677, 1819, 2165, 9961, 1377, 3541, 17381, 15091, 10957, 8180, 5084, 488, 8587, 722, 5612, 8114, 11412, 12993, 6862, 3695, 9161, 17297, 2144, 11812, 17871, 497, 9558, 5865, 1284, 12096, 9647, 13974, 17892, 854, 8259, 1370, 1989, 11560, 12484, 6494, 13813, 15400, 7225, 14578, 3584, 1828, 5818, 382, 13599, 10364, 14045, 389, 716, 17967, 11359, 5842, 10807, 4248, 11775, 7086, 8251, 3029, 13776, 5252, 6401, 15292, 9741, 11067, 16985, 13249, 5179, 3739, 13013, 16151, 17935, 13275, 11807, 10835, 2804, 18183, 6246, 11229, 11482, 3887, 6504, 2475, 15999, 4338, 10275, 5431, 9754, 15042, 17776, 7782, 2422, 11343, 615, 4835, 9658, 7187, 16811, 12141, 10897, 17430, 12790, 13457, 10615, 8480, 16655, 11959, 13261, 435, 17966, 5930, 10772, 3784, 3142, 8462, 543, 8660, 10836, 2589, 7132, 2815, 15162, 10154, 16258, 4366, 12120, 14313, 17756, 14473, 11990, 19, 15036, 366, 10161, 15865, 17996, 5607, 5932, 12971, 16809, 12904, 17731, 1286, 7611, 553, 7182, 6337, 11480, 7459, 16102, 3641, 13574, 13560, 16373, 5926, 709, 4292, 18275, 12684, 18148, 16303, 3765, 5347, 14618, 11144, 2308, 5590, 15386, 8756, 7047, 1282, 4892, 2079, 11044, 16693, 6308, 4298, 3553, 5843, 2110, 1734, 13089, 16262, 13186, 384, 14348, 8200, 8261, 14645, 14366, 5433, 16716, 12463, 12236, 12528, 1694, 4198, 7412, 11134, 17347, 3247, 13389, 14296, 17653, 5563, 1687, 11216, 1924, 11843, 14553, 6654, 14529, 17277, 6881, 598, 2497, 2906, 8432, 13589, 2750, 9279, 7127, 4149, 16052, 7912, 11417, 12740, 4345, 15939, 10851, 5227, 9770, 2954, 12929, 10482, 4839, 8017, 784, 10004, 13661, 13810, 17541, 2030, 16923, 10557, 7664, 11954, 545, 15399, 4001, 7002, 12755, 1006, 7770, 2952, 13202, 8119, 16705, 16892, 16692, 10121, 5459, 16395, 9868, 15762, 16720, 5641, 2858, 6542, 6369, 6473, 16712, 9114, 6624, 15362, 6286, 10132, 6479, 11109, 51, 11425, 12941, 14316, 10784, 2092, 18164, 11087, 3877, 15181, 12171, 6373, 12098, 109, 3036, 2338, 1304, 2899, 926, 13246, 1122, 13212, 18067, 10722, 2808, 5002, 2370, 13601, 16511, 14292, 10361, 10390, 9408, 8721, 14094, 3734, 2829, 260, 15802, 17451, 4073, 12829, 12]\n",
    "\n",
    "# Create a set to store unique random numbers\n",
    "random_numbers = set()\n",
    "\n",
    "# Generate random numbers until we have 4000 unique ones\n",
    "while len(random_numbers) < 100:\n",
    "    rand_num = random.randint(min_range, max_range)\n",
    "    if rand_num not in exclusion_list:\n",
    "        random_numbers.add(rand_num)\n",
    "\n",
    "# Convert the set to a list if needed\n",
    "random_numbers_list = list(random_numbers)\n",
    "\n",
    "# Print the first 10 random numbers as a sample\n",
    "print(random_numbers_list[:10])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "izi8UpBoLXl9"
   },
   "source": [
    "### Loading log files and creating data frames\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "\n",
    "# Mount Google Drive\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "\n",
    "# Random Log file numbers (400)  {HARDCODED FOR EFFICIENCY AND TESTING}\n",
    "file_numbers = random_numbers_list\n",
    "# Path of text file including paths of all log files\n",
    "all_log_files_path = \"all_log_files.txt\"\n",
    "\n",
    "# Creating pandas dataframe of log files from all_log_files.txt with file_numbers number\n",
    "\n",
    "# List of dataframes\n",
    "dfs = []\n",
    "\n",
    "# File number / Line number index\n",
    "i = 0\n",
    "\n",
    "# Open the file in read mode\n",
    "with open(all_log_files_path, 'r') as file:\n",
    "    # Read the file line by line\n",
    "    for line in file:\n",
    "      i += 1\n",
    "      if i > max(file_numbers):\n",
    "        break\n",
    "      if i in file_numbers:\n",
    "        dfs.append( pd.read_csv(line.strip(),low_memory=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-M7h99fCZkyO"
   },
   "source": [
    "### Dropping empty log file dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dth_347WYeIQ",
    "outputId": "9524e51a-e17d-481a-9d1c-cea3c7a0e1bd",
    "tags": []
   },
   "outputs": [],
   "source": [
    "len_before_loop = len(dfs)\n",
    "print('Initial length of dfs = ',len_before_loop)\n",
    "len_after_loop = -1 # For first run of below loop\n",
    "\n",
    "while len_before_loop != len_after_loop:\n",
    "  len_before_loop = len(dfs)\n",
    "  print(\"Initial no. of dataframes = \",len_before_loop)\n",
    "  empty_file_count = 0\n",
    "\n",
    "  i = -1\n",
    "  for df in dfs:\n",
    "    i +=1\n",
    "    if dfs[i].empty : #if len(df) == 0:\n",
    "      empty_file_count +=1\n",
    "      print(\"Empty file found! Total = \",empty_file_count)\n",
    "      del dfs[i]\n",
    "\n",
    "  len_after_loop = len(dfs)\n",
    "  print(\"Final no. of dataframes = \",len_after_loop)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tG8jCgB9fhKV"
   },
   "source": [
    "### Template based approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import itertools\n",
    "import gensim\n",
    "\n",
    "# List of dataframes\n",
    "# dfs = dfs\n",
    "\n",
    "# Define a function to clean and preprocess column names\n",
    "def clean_and_preprocess(col_names):\n",
    "    cleaned_cols = []\n",
    "    for col in col_names:\n",
    "        # Clean and preprocess the column name using gensim\n",
    "        cleaned_col = gensim.utils.simple_preprocess(col)\n",
    "        cleaned_cols.extend(cleaned_col)\n",
    "    return cleaned_cols\n",
    "\n",
    "# Define a function to calculate the similarity between two lists of strings   <---------- Jaccard\n",
    "def similarity(list1, list2):\n",
    "    common_elements = set(list1) & set(list2)\n",
    "    total_elements = set(list1) | set(list2)\n",
    "    return len(common_elements) / len(total_elements)\n",
    "\n",
    "# Initialize clusters\n",
    "clusters = []\n",
    "\n",
    "# Cluster dataframes based on cleaned and preprocessed column name similarity\n",
    "for (df1_num, df1), (df2_num, df2) in itertools.combinations(enumerate(dfs), 2):\n",
    "    column_names1 = df1.columns.tolist()\n",
    "    column_names2 = df2.columns.tolist()\n",
    "    \n",
    "    # Clean and preprocess column names\n",
    "    cleaned_columns1 = clean_and_preprocess(column_names1)\n",
    "    cleaned_columns2 = clean_and_preprocess(column_names2)\n",
    "    \n",
    "    sim_score = similarity(cleaned_columns1, cleaned_columns2)\n",
    "    \n",
    "    if sim_score >= 0.8:\n",
    "        # Check if dataframes belong to existing clusters\n",
    "        merged = False\n",
    "        for cluster in clusters:\n",
    "            if df1_num in cluster or df2_num in cluster:\n",
    "                cluster.add(df1_num)\n",
    "                cluster.add(df2_num)\n",
    "                merged = True\n",
    "                break\n",
    "        \n",
    "        if not merged:\n",
    "            # Create a new cluster\n",
    "            new_cluster = set([df1_num, df2_num])\n",
    "            clusters.append(new_cluster)\n",
    "\n",
    "            \n",
    "\n",
    "# Print the clusters\n",
    "for i, cluster in enumerate(clusters):\n",
    "    print(f\"Cluster {i+1} length :\",len(cluster))\n",
    "    \n",
    "    for df in cluster: \n",
    "        print(df)\n",
    "    \n",
    "       \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a histogram for the number of dataframes in each cluster\n",
    "cluster_sizes = [len(cluster) for cluster in clusters]\n",
    "cluster_labels = [f\"Cluster {i+1}\" for i in range(len(clusters))]\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(cluster_labels, cluster_sizes)\n",
    "plt.xlabel('Clusters')\n",
    "plt.ylabel('Number of Dataframes')\n",
    "plt.title('Number of Dataframes in Each Cluster')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
